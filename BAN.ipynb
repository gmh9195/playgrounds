{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1SUUKhrKCXI"
      },
      "source": [
        "This notebook demonstates how to distill pre-trained neural network with born-again neural network (BAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gvXLyvgvZ0-E"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "from collections import OrderedDict, defaultdict\n",
        "from typing import Union, List\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import *\n",
        "from torchvision.transforms import *\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "assert torch.cuda.is_available(), \\\n",
        "\"The current runtime does not have CUDA support.\" \\\n",
        "\"Please go to menu bar (Runtime - Change runtime type) and select GPU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-0vuvsWnaD6U"
      },
      "outputs": [],
      "source": [
        "### create class object VGG to identify the pretrained model architecture\n",
        "class VGG(nn.Module):\n",
        "  ARCH = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "    counts = defaultdict(int)\n",
        "\n",
        "    def add(name: str, layer: nn.Module) -> None:\n",
        "      layers.append((f\"{name}{counts[name]}\", layer))\n",
        "      counts[name] += 1\n",
        "\n",
        "    in_channels = 3\n",
        "    for x in self.ARCH:\n",
        "      if x != 'M':\n",
        "        # conv-bn-relu\n",
        "        add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n",
        "        add(\"bn\", nn.BatchNorm2d(x))\n",
        "        add(\"relu\", nn.ReLU(True))\n",
        "        in_channels = x\n",
        "      else:\n",
        "        # maxpool\n",
        "        add(\"pool\", nn.MaxPool2d(2))\n",
        "\n",
        "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
        "    self.classifier = nn.Linear(512, 10)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    # backbone: [N, 3, 32, 32] => [N, 512, 2, 2]\n",
        "    x = self.backbone(x)\n",
        "\n",
        "    # avgpool: [N, 512, 2, 2] => [N, 512]\n",
        "    x = x.mean([2, 3])\n",
        "\n",
        "    # classifier: [N, 512] => [N, 10]\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKrLoupxbcoI",
        "outputId": "781c87aa-7df4-4fe9-d1eb-ee69216849ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "### load pretrained model\n",
        "checkpoint=torch.load(\"./vgg.cifar.pretrained.pth\",map_location=\"cpu\")\n",
        "model = VGG().cuda()\n",
        "\n",
        "model.load_state_dict(checkpoint['state_dict'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae37VJhOdpVw",
        "outputId": "589afaeb-13fb-4518-acb0-3c538a3590ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "### create train and test dataset\n",
        "image_size = 32\n",
        "transforms = {\n",
        "    \"train\": Compose([\n",
        "        RandomCrop(image_size, padding=4),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "    ]),\n",
        "    \"test\": ToTensor(),\n",
        "}\n",
        "dataset = {}\n",
        "for split in [\"train\", \"test\"]:\n",
        "  dataset[split] = CIFAR10(\n",
        "    root=\"data/cifar10\",\n",
        "    train=(split == \"train\"),\n",
        "    download=True,\n",
        "    transform=transforms[split],\n",
        "  )\n",
        "dataloader = {}\n",
        "for split in ['train', 'test']:\n",
        "  dataloader[split] = DataLoader(\n",
        "    dataset[split],\n",
        "    batch_size=512,\n",
        "    shuffle=(split == 'train'),\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "in7F6epaAc22"
      },
      "outputs": [],
      "source": [
        "### create class object for BornAgainNN distillation\n",
        "class BornAgainNN:\n",
        "  def __init__(self,model,model_class,lr,train_loader, test_loader,alpha=0.4, T=5):\n",
        "    self.VGG=model_class\n",
        "    self.pretrained_model=model\n",
        "\n",
        "    self.lr=lr\n",
        "\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.kd_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
        "    self.train_loader=train_loader\n",
        "    self.test_loader=test_loader\n",
        "    self.alpha=alpha\n",
        "    self.T=T\n",
        "\n",
        "  def train_generation(self,student, teacher, epochs):\n",
        "    teacher.eval()\n",
        "    optimizer = Adam(student.parameters(), lr=self.lr)\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for images, labels in self.train_loader:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            student_logits = student(images)\n",
        "\n",
        "            if teacher:\n",
        "                with torch.no_grad():\n",
        "                    teacher_logits = teacher(images)\n",
        "\n",
        "                # Soft targets\n",
        "                soft_student = F.log_softmax(student_logits / self.T, dim=1)\n",
        "                soft_teacher = F.softmax(teacher_logits / self.T, dim=1)\n",
        "\n",
        "                loss_kd = self.kd_loss_fn(soft_student, soft_teacher) * self.T * self.T\n",
        "                loss_ce = self.criterion(student_logits, labels)\n",
        "                loss = self.alpha * loss_ce + (1 - self.alpha) * loss_kd\n",
        "            else:\n",
        "                loss = self.criterion(student_logits, labels)\n",
        "\n",
        "            optimizer.zero_grad() ## reset gradients\n",
        "            loss.backward() ### update gradients\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n",
        "    return student\n",
        "\n",
        "\n",
        "  def run_generation(self,epoch=7,generation=3):\n",
        "\n",
        "\n",
        "    teacher = self.pretrained_model\n",
        "\n",
        "    #acc = self.evaluate(teacher)\n",
        "\n",
        "\n",
        "    for i in range(generation):\n",
        "      student = self.VGG().cuda()\n",
        "      student.load_state_dict(checkpoint['state_dict'])\n",
        "      student = self.train_generation(student, teacher, epochs=epoch)\n",
        "      acc = self.evaluate(student)\n",
        "      # Teacher for next generation is current student\n",
        "      teacher = copy.deepcopy(student)\n",
        "\n",
        "      with open(\"log.txt\",\"a\") as file:\n",
        "        file.write(f\"generation {i +1}, Accuracy: {acc}\")\n",
        "\n",
        "  def evaluate(self, model):\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in self.test_loader:\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        acc = correct / total\n",
        "        print(f\"Accuracy: {acc:.4f}\")\n",
        "        return acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LcpPMV89lBO2"
      },
      "outputs": [],
      "source": [
        "trainer = BornAgainNN(\n",
        "    model=model,\n",
        "\n",
        "    model_class=VGG,\n",
        "    lr=0.002,\n",
        "    train_loader=dataloader[\"train\"],\n",
        "    test_loader=dataloader[\"test\"],\n",
        "\n",
        ")\n",
        "\n",
        "trainer.run_generation(epoch=5,generation=3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}